{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe_SA3n0I3T8"
      },
      "source": [
        "import pickle\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.neural_network import MLPRegressor as mlp\n",
        "from IPython.display import display\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTagdmneHA5f",
        "outputId": "dc883291-2c95-40d6-cc20-6cd385979c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1g4I5ARGTp",
        "outputId": "b7f17ad1-5620-459a-999a-a680bab2576f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKpe_KPRLrn"
      },
      "source": [
        "# change to path to dataset\n",
        "file_name = \"/content/cnn_dataset_1000_labelled.pkl\"\n",
        "stories = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stories[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4rBK7w30nz0",
        "outputId": "cab658f6-9765-4336-ea15-125ed8a77a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'story': [\"potomac, maryland (cnn) -- to combat the depression and despair during her 105-day stint in iran's notorious evin prison, haleh esfandiari welcomed all distractions and blocked thoughts of her beloved home and family.\",\n",
              "  'haleh esfandiari talks to iranian media in front of evin prison after her august 21 release.',\n",
              "  'the iranian-american scholar, who was charged with espionage and endangering iranian national security during a december visit to her family, wrote a book in her mind, read newspapers, watched television and exercised voraciously.',\n",
              "  '\"i decided either i am going to succumb to despair or i am going to try to make the best of this condition, and the best of this condition was to have a disciplined day,\" she said. \"so i would exercise for many hours, i would read, i would walk a lot, some three to four hours a day -- even in the room, you know, i would pace up and down timing myself.\"',\n",
              "  'the 67-year-old grandmother of two said dwelling on her incarceration, and longing for her family, was disheartening \"so that\\'s why i plunged into exercising, and i wrote a book in my mind on the history and life story of my grandmother. as i would be walking, i would write chapters and edit them in my mind and rewrite it the next day.\" watch an \\'elated\\' esfandiari explain how she passed the time »',\n",
              "  'esfandiari said she was treated \"with respect\" while at evin, but added, \"a prison is a prison.\"',\n",
              "  'esfandiari was allowed to go home last week. she returned to potomac, maryland, on thursday and discussed her arrest and captivity during a saturday interview.',\n",
              "  \"though she said she's unsure why she was jailed in evin's political wing, esfandiari believes her iranian captors wanted to know more about the woodrow wilson center for international scholars, the washington-based think tank where she heads the middle east program.\",\n",
              "  '\"i think they were trying to found out more about the wilson center -- what it really does, were trying to find out about think tanks in america, foundations in america, the relationship between think tanks, foundations and the government,\" she said.',\n",
              "  'on december 21, the dual iranian-american national traveled to iran to visit her 93-year-old mother, where she visited for nine days. on december 30, she caught a taxi to the airport where she planned to fly home to washington.',\n",
              "  'those plans were altered by three knife-wielding men who stopped her cab, threatened to kill her and stole her luggage and handbag, which contained both of her passports and her airline ticket.',\n",
              "  'esfandiari called her husband, shaul bakhash, back home in maryland and told him to cancel her credit cards and report the stolen passport. the next day, she went to the authorities.',\n",
              "  '\"i went to the passport office, and they said that they would like to, somebody wants to talk to you. and that was the beginning of the saga,\" she said.',\n",
              "  \"that somebody, according to the wilson center, was an official with iran's ministry of intelligence.\",\n",
              "  'beginning on january 4, esfandiari was subjected to weeks of interrogations, sometimes as many as four a week and some lasting as long as eight hours, according to the wilson center. the questioning, the center said, was \"unpleasant and not free from intimidation and threat.\"',\n",
              "  \"she was pressured to make confessions and falsely implicate the wilson center. she once received a threatening phone call. on january 18, she awoke from a nap at her mother's home to find her interrogator and two men -- one of them wielding a video camera -- staring into her bedroom, the wilson center said.\",\n",
              "  'on february 17, the interrogations stopped, but in late april or early may she again began receiving phone calls from the iranian government. on may 7, she was asked to go to the ministry of intelligence the following morning, according to the wilson center.',\n",
              "  'when she arrived, she was put in a car and taken to evin prison. over the next two weeks, iranian media reported that esfandiari was accused of trying to topple the iranian government.',\n",
              "  'later that month, a judiciary spokesperson announced that she was charged with espionage, actions against national security and propaganda against the islamic republic.',\n",
              "  '\"it was puzzling for me at first,\" esfandiari told cnn. \"i think there is a concern among certain elements that the united states has planned some kind of velvet revolution in iran, and since they are bogged down in iraq and afghanistan, they won\\'t do it through military. they would do [it] through think tanks and foundations to create a network of people to undermine the regime. i think that is their concern.\"',\n",
              "  \"the velvet revolution is the name given to the 1989 bloodless coup that saw czechoslovakia's communist regime overthrown.\",\n",
              "  'in prison, esfandiari was interviewed for an iranian state television documentary, in which she allegedly linked u.s. think tanks and nongovernmental organizations with a \"soft revolution\" against the iranian government.',\n",
              "  'the wilson center quickly denounced the documentary as \"scripted, contrived, and completely without merit.\"',\n",
              "  'the center\\'s president and director, lee hamilton, who has served on the 9/11 commission and iraq study group, also issued a statement, saying the documentary took \"the fabrication of news to a new art form. this is shameful. it cannot be considered a \\'confession\\' by any stretch of the imagination.\"',\n",
              "  \"hamilton had written letters to president mahmoud ahmadinejad and majlis speaker shouray-e-islami, to no avail. on june 29, he wrote another letter to grand ayatollah ali khamenei, the supreme leader of iran, pleading for his help in esfandiari's case.\",\n",
              "  'a week later, the former congressman met in new york with iran\\'s representative to the u.n., who delivered a written response from khamenei. the letter, which \"was positive and conveyed respect,\" marked the first time the ayatollah had responded to an american leader, according to the wilson center.',\n",
              "  \"esfandiari said she believes she owes her freedom, in part, to hamilton's letter. the iranian government never said why esfandiari was allowed to go home, but on august 21 she was released on a bail of 3 billion iranian rials ($320,000).\",\n",
              "  'esfandiari picked up her passport september 1 and flew to vienna, austria, where her sister lives, the next day. she arrived in the united states on thursday.',\n",
              "  '\"the first thing i did, i walked around, walked into the kitchen and started looking at things and say, \\'ok, where is this? this shouldn\\'t be here! that shouldn\\'t be there!\\' \" she said. \"and shaul goes, \\'there she goes again.\\' \"',\n",
              "  'esfandiari said she is \"elated to be home.\"',\n",
              "  '\"sleeping in my own bed after eight months, taking a shower in my own bathroom after eight months, walking around the garden,\" she said. \"to see my grandchildren who have grown since i last saw them in those eight months. so it is a fantastic -- it is a fantastic feeling -- and looking back, i am glad this nightmare is over.\" e-mail to a friend'],\n",
              " 'highlights': ['haleh esfandiari says she read, walked, wrote a book in her mind while in prison',\n",
              "  'scholar arrived home thursday after iran forbade her to leave for eight months',\n",
              "  'iranian government never said why they released esfandiari from jail last month',\n",
              "  \"wilson center: ayatollah's letter marked first-ever response to american leader\"],\n",
              " 'story_text': 'potomac, maryland (cnn) -- to combat the depression and despair during her 105-day stint in iran\\'s notorious evin prison, haleh esfandiari welcomed all distractions and blocked thoughts of her beloved home and family..haleh esfandiari talks to iranian media in front of evin prison after her august 21 release..the iranian-american scholar, who was charged with espionage and endangering iranian national security during a december visit to her family, wrote a book in her mind, read newspapers, watched television and exercised voraciously..\"i decided either i am going to succumb to despair or i am going to try to make the best of this condition, and the best of this condition was to have a disciplined day,\" she said. \"so i would exercise for many hours, i would read, i would walk a lot, some three to four hours a day -- even in the room, you know, i would pace up and down timing myself.\".the 67-year-old grandmother of two said dwelling on her incarceration, and longing for her family, was disheartening \"so that\\'s why i plunged into exercising, and i wrote a book in my mind on the history and life story of my grandmother. as i would be walking, i would write chapters and edit them in my mind and rewrite it the next day.\" watch an \\'elated\\' esfandiari explain how she passed the time ».esfandiari said she was treated \"with respect\" while at evin, but added, \"a prison is a prison.\".esfandiari was allowed to go home last week. she returned to potomac, maryland, on thursday and discussed her arrest and captivity during a saturday interview..though she said she\\'s unsure why she was jailed in evin\\'s political wing, esfandiari believes her iranian captors wanted to know more about the woodrow wilson center for international scholars, the washington-based think tank where she heads the middle east program..\"i think they were trying to found out more about the wilson center -- what it really does, were trying to find out about think tanks in america, foundations in america, the relationship between think tanks, foundations and the government,\" she said..on december 21, the dual iranian-american national traveled to iran to visit her 93-year-old mother, where she visited for nine days. on december 30, she caught a taxi to the airport where she planned to fly home to washington..those plans were altered by three knife-wielding men who stopped her cab, threatened to kill her and stole her luggage and handbag, which contained both of her passports and her airline ticket..esfandiari called her husband, shaul bakhash, back home in maryland and told him to cancel her credit cards and report the stolen passport. the next day, she went to the authorities..\"i went to the passport office, and they said that they would like to, somebody wants to talk to you. and that was the beginning of the saga,\" she said..that somebody, according to the wilson center, was an official with iran\\'s ministry of intelligence..beginning on january 4, esfandiari was subjected to weeks of interrogations, sometimes as many as four a week and some lasting as long as eight hours, according to the wilson center. the questioning, the center said, was \"unpleasant and not free from intimidation and threat.\".she was pressured to make confessions and falsely implicate the wilson center. she once received a threatening phone call. on january 18, she awoke from a nap at her mother\\'s home to find her interrogator and two men -- one of them wielding a video camera -- staring into her bedroom, the wilson center said..on february 17, the interrogations stopped, but in late april or early may she again began receiving phone calls from the iranian government. on may 7, she was asked to go to the ministry of intelligence the following morning, according to the wilson center..when she arrived, she was put in a car and taken to evin prison. over the next two weeks, iranian media reported that esfandiari was accused of trying to topple the iranian government..later that month, a judiciary spokesperson announced that she was charged with espionage, actions against national security and propaganda against the islamic republic..\"it was puzzling for me at first,\" esfandiari told cnn. \"i think there is a concern among certain elements that the united states has planned some kind of velvet revolution in iran, and since they are bogged down in iraq and afghanistan, they won\\'t do it through military. they would do [it] through think tanks and foundations to create a network of people to undermine the regime. i think that is their concern.\".the velvet revolution is the name given to the 1989 bloodless coup that saw czechoslovakia\\'s communist regime overthrown..in prison, esfandiari was interviewed for an iranian state television documentary, in which she allegedly linked u.s. think tanks and nongovernmental organizations with a \"soft revolution\" against the iranian government..the wilson center quickly denounced the documentary as \"scripted, contrived, and completely without merit.\".the center\\'s president and director, lee hamilton, who has served on the 9/11 commission and iraq study group, also issued a statement, saying the documentary took \"the fabrication of news to a new art form. this is shameful. it cannot be considered a \\'confession\\' by any stretch of the imagination.\".hamilton had written letters to president mahmoud ahmadinejad and majlis speaker shouray-e-islami, to no avail. on june 29, he wrote another letter to grand ayatollah ali khamenei, the supreme leader of iran, pleading for his help in esfandiari\\'s case..a week later, the former congressman met in new york with iran\\'s representative to the u.n., who delivered a written response from khamenei. the letter, which \"was positive and conveyed respect,\" marked the first time the ayatollah had responded to an american leader, according to the wilson center..esfandiari said she believes she owes her freedom, in part, to hamilton\\'s letter. the iranian government never said why esfandiari was allowed to go home, but on august 21 she was released on a bail of 3 billion iranian rials ($320,000)..esfandiari picked up her passport september 1 and flew to vienna, austria, where her sister lives, the next day. she arrived in the united states on thursday..\"the first thing i did, i walked around, walked into the kitchen and started looking at things and say, \\'ok, where is this? this shouldn\\'t be here! that shouldn\\'t be there!\\' \" she said. \"and shaul goes, \\'there she goes again.\\' \".esfandiari said she is \"elated to be home.\".\"sleeping in my own bed after eight months, taking a shower in my own bathroom after eight months, walking around the garden,\" she said. \"to see my grandchildren who have grown since i last saw them in those eight months. so it is a fantastic -- it is a fantastic feeling -- and looking back, i am glad this nightmare is over.\" e-mail to a friend.',\n",
              " 'scores': [0.0014025244075858419,\n",
              "  0.002224693943462096,\n",
              "  0.005610098040124401,\n",
              "  0.0,\n",
              "  0.0022246940174480835,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0011947430255763623,\n",
              "  0.0015003749709520506,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0015735639960852898,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.00506008844241049,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.000827129775402439]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhUQTVpk1N7S",
        "outputId": "da006092-accc-47e5-db40-a4c051236749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-29 04:28:47.019319: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-29 04:28:47.019406: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-29 04:28:47.022145: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-29 04:28:48.707383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.6.0/en_core_web_lg-3.6.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-_iuFDvZTvi"
      },
      "source": [
        "import spacy\n",
        "embedder = spacy.load('en_core_web_lg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEsDrJHUTOxY"
      },
      "source": [
        "# basic embeddings using averaged glove vectors\n",
        "# using Spacy's large language model\n",
        "def get_embedding(text):\n",
        "    extract = embedder(text)\n",
        "    total_sum = np.zeros(300)\n",
        "    count = 0\n",
        "    for token in extract:\n",
        "        count += 1\n",
        "        total_sum += np.asarray(token.vector)\n",
        "    return total_sum / count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26X4T5jHRLpw",
        "outputId": "3996ca7a-0fc5-4d08-ab9f-1192f0a9ff85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# creating the inputs and expected outputs\n",
        "train_size = 900\n",
        "val_size = 50\n",
        "test_size = 50\n",
        "\n",
        "def make_set(start_index, size):\n",
        "    count = 0\n",
        "    X_set = []\n",
        "    y_set = []\n",
        "\n",
        "    for count in tqdm(range(size)):\n",
        "        data = stories[start_index + count]\n",
        "\n",
        "        doc_emb = get_embedding(data['story_text'])\n",
        "\n",
        "        index = 0\n",
        "        for sentence in data['story']:\n",
        "            sent_emb = get_embedding(sentence)\n",
        "\n",
        "            x = np.concatenate((sent_emb, doc_emb))\n",
        "            try:\n",
        "                y = data['scores'][index]\n",
        "            except:\n",
        "                y = 0.0\n",
        "            index += 1\n",
        "\n",
        "            X_set.append(x)\n",
        "            y_set.append(y)\n",
        "\n",
        "    return np.asmatrix(X_set), np.asarray(y_set)\n",
        "\n",
        "X_train, y_train = make_set(0, train_size)\n",
        "X_val, y_val = make_set(train_size, val_size)\n",
        "X_test, y_test = make_set(train_size + val_size, test_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 900/900 [08:17<00:00,  1.81it/s]\n",
            "100%|██████████| 50/50 [00:24<00:00,  2.02it/s]\n",
            "100%|██████████| 50/50 [00:39<00:00,  1.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY6JkXtWWOwm"
      },
      "source": [
        "def get_values(X, model):\n",
        "    X_array = np.asarray(X)\n",
        "    return model.predict(X_array)\n",
        "\n",
        "def get_loss(pred, y):\n",
        "    return np.linalg.norm(pred - y) / np.shape(y)[0]\n",
        "\n",
        "model_name = \"extractive_summarizer\"\n",
        "\n",
        "def make_parameters(train_size):\n",
        "    batch_size = 256\n",
        "    n_batches = int(4 * (train_size / batch_size))\n",
        "\n",
        "    print(\"Total Number of Training Examples: \" + str(train_size))\n",
        "    print(\"Batch Size: \" + str(batch_size))\n",
        "    print(\"Number of Batches: \" + str(n_batches))\n",
        "\n",
        "    return batch_size, n_batches\n",
        "\n",
        "def train(X_train, y_train, batch_size, n_batches):\n",
        "    model = mlp(hidden_layer_sizes = (1024, 2048, 1024, 512, 256, 256, 128, 64), max_iter = 1000)\n",
        "\n",
        "    train_size = np.shape(X_train)[0]\n",
        "\n",
        "    min_loss = 1e20\n",
        "\n",
        "    for iterator in tqdm(range(n_batches)):\n",
        "        idx = np.random.randint(0, train_size, size = batch_size)\n",
        "\n",
        "        X_select = X_train[idx,:]\n",
        "        y_select = y_train[idx]\n",
        "\n",
        "        model.partial_fit(X_select, y_select)\n",
        "\n",
        "        sentence_predicted_scores = get_values(X_val, model)\n",
        "\n",
        "        loss = get_loss(sentence_predicted_scores, y_val)\n",
        "\n",
        "        # saving best model seen so far\n",
        "        if loss < min_loss:\n",
        "            min_loss = loss\n",
        "            pickle.dump(model, open(model_name + '_best_model', 'wb'))\n",
        "\n",
        "    final_model = pickle.load(open(model_name + '_best_model', 'rb'))\n",
        "    drive_path = '/content/drive/MyDrive/extractive_summarizer.pkl'\n",
        "    with open(drive_path, 'wb') as file:\n",
        "        pickle.dump(final_model, file)\n",
        "    return final_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrX21q4u8ukA",
        "outputId": "d81ca321-1aa3-484f-8827-36af79e31716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_count = y_train.shape[0]\n",
        "batch_size, n_batches = make_parameters(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Training Examples: 19223\n",
            "Batch Size: 256\n",
            "Number of Batches: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZzWH2VWaQjZ",
        "outputId": "8574fab0-7407-4313-bb97-f911bb02c1e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = train(np.array(X_train), 1000 * y_train, batch_size, n_batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [07:11<00:00,  1.44s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl4yFkiyiTa_"
      },
      "source": [
        "# Hyperparameter for similarity threshold\n",
        "theta = 0.95\n",
        "\n",
        "def similarity(A, B):\n",
        "    similarity =  (A @ B.T) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
        "    return similarity\n",
        "\n",
        "def get_top_k(X_doc, y, k):\n",
        "    order = np.flip(np.argsort(y))\n",
        "    sentence_set = []\n",
        "    for sent_id in order:\n",
        "        if sentence_set == []:\n",
        "            sentence_set.append(order[0])\n",
        "            continue\n",
        "\n",
        "        consider = X_doc[sent_id, :]\n",
        "        flag = 1\n",
        "        for consider_id in sentence_set:\n",
        "            if similarity(X_doc[consider_id, :], consider) > theta:\n",
        "                flag = 0\n",
        "                break\n",
        "\n",
        "        if flag == 1:\n",
        "            sentence_set.append(sent_id)\n",
        "    return sentence_set[0: min(k, len(sentence_set))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_zjPWDVG179"
      },
      "source": [
        "# Creating object of the ROUGE class\n",
        "rouge = Rouge()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph6OFgGwcewS",
        "outputId": "34ff9e81-bf8a-4ada-a809-ad9e8cdf50e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# evaluation\n",
        "# testing out each document iteratively\n",
        "# test set: document 'train_size + val_size' onwards\n",
        "\n",
        "def join(lst):\n",
        "    string = \"\"\n",
        "    for elem in lst:\n",
        "        string = string + elem + \" . \"\n",
        "    return string\n",
        "\n",
        "def extract_rouge(rouge_dict):\n",
        "    scores = []\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-1\"]['r'])\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-2\"]['r'])\n",
        "\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['f'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['p'])\n",
        "    scores.append(100 * rouge_dict[\"rouge-l\"]['r'])\n",
        "\n",
        "    return np.asarray(scores)\n",
        "\n",
        "start_doc_id = train_size + val_size\n",
        "doc_count = len(stories)\n",
        "\n",
        "generated_summary, gold_summary = 0, 0\n",
        "\n",
        "# set the number of documents for testing\n",
        "limit = test_size\n",
        "\n",
        "result = {}\n",
        "result['3'] = np.zeros(9)\n",
        "result['4'] = np.zeros(9)\n",
        "result['5'] = np.zeros(9)\n",
        "# averaging the ROUGE Metrics\n",
        "# for different summary lengths\n",
        "\n",
        "count = 0\n",
        "all_summaries = []\n",
        "\n",
        "while count < min(doc_count, limit):\n",
        "    X_doc = []\n",
        "    y_doc = []\n",
        "    data = stories[start_doc_id + count]\n",
        "    doc_emb = get_embedding(data['story_text'])\n",
        "\n",
        "    index = 0\n",
        "    for sentence in data['story']:\n",
        "        sent_emb = get_embedding(sentence)\n",
        "\n",
        "        x = np.concatenate((sent_emb, doc_emb))\n",
        "        try:\n",
        "            y = data['scores'][index]\n",
        "        except:\n",
        "            y = 0.0\n",
        "\n",
        "        index += 1\n",
        "\n",
        "        X_doc.append(x)\n",
        "        y_doc.append(y)\n",
        "\n",
        "    X_doc = np.asmatrix(X_doc)\n",
        "    y_doc = np.asarray(y_doc)\n",
        "\n",
        "    sentence_predicted_scores = get_values(X_doc, model)\n",
        "\n",
        "    loss = np.linalg.norm(sentence_predicted_scores - y_doc)\n",
        "\n",
        "    print(loss)\n",
        "\n",
        "    gold_summary = join(data['highlights'])\n",
        "\n",
        "    for k in [3, 4, 5]:\n",
        "        summary_sent_id = get_top_k(X_doc, sentence_predicted_scores, k)\n",
        "\n",
        "        generated_summary = join([data['story'][idx] for idx in summary_sent_id])\n",
        "\n",
        "        scores = rouge.get_scores(generated_summary, gold_summary)[0]\n",
        "        result[str(k)] += extract_rouge(scores)\n",
        "\n",
        "    summary_eval = {'doc': data['story_text'], 'gen_summ': generated_summary, 'true_summ': gold_summary}\n",
        "    all_summaries.append(summary_eval)\n",
        "\n",
        "    count += 1\n",
        "\n",
        "for k in [3, 4, 5]:\n",
        "    result[str(k)] = result[str(k)] / test_size\n",
        "\n",
        "predicted = get_values(X_test, model)\n",
        "test_loss = get_loss(y_test, predicted)\n",
        "\n",
        "print(\"Sample Output:\")\n",
        "print(\"Document:\\n\", stories[-1]['story_text'])\n",
        "print(\"Generated Summary:\\n\", generated_summary)\n",
        "print(\"Gold Summary:\\n\", gold_summary)\n",
        "\n",
        "print(\"\\nAll Metrics:\\n\")\n",
        "\n",
        "data = []\n",
        "for k in [3, 4, 5]:\n",
        "    lst = np.ndarray.tolist(result[str(k)])\n",
        "    lst.append(test_loss)\n",
        "    data.append(lst)\n",
        "\n",
        "df = pd.DataFrame(data, columns = ['R1-f', 'R1-p', 'R1-r',\n",
        "                                    'R2-f', 'R2-p', 'R2-r',\n",
        "                                    'Rl-f', 'Rl-p', 'Rl-r',\n",
        "                                    'Loss'], dtype = float)\n",
        "\n",
        "df.index = ['glove top-3', 'glove top-4', 'glove top-5']\n",
        "display(df)\n",
        "\n",
        "# save results into a dataframe file\n",
        "# df.to_csv(model_name + '_results.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.097774754062668\n",
            "3.375584823216594\n",
            "3.1262355444243584\n",
            "4.2112417264576525\n",
            "2.283424486765786\n",
            "2.481217421137601\n",
            "1.833497198126616\n",
            "3.856162822917234\n",
            "1.9256955350652396\n",
            "1.9541386672276198\n",
            "2.9774919755620313\n",
            "1.692843118200946\n",
            "1.7203849897004655\n",
            "4.993715811102012\n",
            "3.067279556557946\n",
            "2.4520579801859843\n",
            "2.8467154027430146\n",
            "2.5651704386178755\n",
            "3.211432967830303\n",
            "2.3813479910990134\n",
            "3.237939536766949\n",
            "3.1839254145149667\n",
            "5.307474274982902\n",
            "2.811395233803725\n",
            "2.221701780375956\n",
            "3.1519597292489157\n",
            "3.713573460475412\n",
            "3.0763492313582397\n",
            "3.4682471975128277\n",
            "2.891407630077076\n",
            "2.9195640958425026\n",
            "5.1567066241146815\n",
            "3.572749656817841\n",
            "2.543769322202955\n",
            "5.11975857177629\n",
            "2.906958366781263\n",
            "2.6965679444143102\n",
            "4.037941896874088\n",
            "2.001659453318919\n",
            "2.97994376965974\n",
            "3.054287737049449\n",
            "3.6770749075014284\n",
            "2.459209341254176\n",
            "2.493887556422647\n",
            "3.747481188716583\n",
            "3.038710813228341\n",
            "3.243248651958497\n",
            "2.6464417598554038\n",
            "3.6702100637558854\n",
            "2.1990987077359\n",
            "Sample Output:\n",
            "Document:\n",
            " -- in the wake of the earthquake in haiti, george clooney and other celebrities have signed on for a telethon to aid the devastated island nation..the oscar-winning actor will take part in a fundraising program to air commercial-free across several networks, mtv announced..\"hope for haiti now\" will air on abc, cbs, nbc, fox, cnn, bet, the cw, hbo, mtv, vh1 and cmt starting at 8 p.m. et/pt and 7 p.m. ct on friday, january 22..mtv said clooney will serve as a host in los angeles, while musician wyclef jean will be in new york, and cnn's anderson cooper will appear from haiti..the two-hour event will feature as-yet-unnamed musical performances and celebrity appearances, as well as live news reports from cnn..it's hollywood's latest philanthropic gesture in reaction to the catastrophic situation in haiti..a celebrity lounge at this weekend's golden globe awards in beverly hills has been turned into a haitian aid fundraiser..medecins sans frontieres says actors angelina jolie and brad pitt have donated $1 million to the group's emergency medical operation as it responds to the disaster..full coverage of the earthquake in haiti.tuesday's 7.0 earthquake has devastated the poverty-stricken country's infrastructure. haitian president rene preval said wednesday that he had heard estimates of up to 50,000 dead but that it was too early to know for sure..damage has closed the port and limited airport operations in the capital city of port-au-prince, and the quake buckled many roads, making it extremely difficult for aid groups to bring in emergency supplies and search for survivors in the rubble..mtv said all proceeds from the telethon will be split evenly among seven relief organizations currently operating in haiti: clinton-bush haiti fund, oxfam america, partners in health, the red cross, unicef and yele haiti foundation and world food programme..\n",
            "Generated Summary:\n",
            " damage has closed the port and limited airport operations in the capital city of port-au-prince, and the quake buckled many roads, making it extremely difficult for aid groups to bring in emergency supplies and search for survivors in the rubble. . full coverage of the earthquake in haiti . tuesday's 7.0 earthquake has devastated the poverty-stricken country's infrastructure. haitian president rene preval said wednesday that he had heard estimates of up to 50,000 dead but that it was too early to know for sure. . the two-hour event will feature as-yet-unnamed musical performances and celebrity appearances, as well as live news reports from cnn. . medecins sans frontieres says actors angelina jolie and brad pitt have donated $1 million to the group's emergency medical operation as it responds to the disaster. . \n",
            "Gold Summary:\n",
            " fundraising program to be telecast on numerous networks on friday, january 22 . all proceeds will be split among five relief organizations . other celebrities have already launched efforts to aid quake-ravaged haiti . \n",
            "\n",
            "All Metrics:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  R1-f       R1-p       R1-r      R2-f      R2-p      R2-r  \\\n",
              "glove top-3  20.585508  17.175541  28.386594  3.572463  2.834532  5.311748   \n",
              "glove top-4  20.575442  15.719621  33.385626  4.020607  2.924329  7.799534   \n",
              "glove top-5  20.861253  15.091167  37.972931  4.497306  3.088513  9.974654   \n",
              "\n",
              "                  Rl-f       Rl-p       Rl-r      Loss  \n",
              "glove top-3  19.324870  16.171924  26.582053  0.021697  \n",
              "glove top-4  19.272610  14.749915  31.202568  0.021697  \n",
              "glove top-5  19.607727  14.198037  35.709369  0.021697  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-222b47f5-d4a6-47c6-90c3-c3bbb7e0c1a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R1-f</th>\n",
              "      <th>R1-p</th>\n",
              "      <th>R1-r</th>\n",
              "      <th>R2-f</th>\n",
              "      <th>R2-p</th>\n",
              "      <th>R2-r</th>\n",
              "      <th>Rl-f</th>\n",
              "      <th>Rl-p</th>\n",
              "      <th>Rl-r</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>glove top-3</th>\n",
              "      <td>20.585508</td>\n",
              "      <td>17.175541</td>\n",
              "      <td>28.386594</td>\n",
              "      <td>3.572463</td>\n",
              "      <td>2.834532</td>\n",
              "      <td>5.311748</td>\n",
              "      <td>19.324870</td>\n",
              "      <td>16.171924</td>\n",
              "      <td>26.582053</td>\n",
              "      <td>0.021697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>glove top-4</th>\n",
              "      <td>20.575442</td>\n",
              "      <td>15.719621</td>\n",
              "      <td>33.385626</td>\n",
              "      <td>4.020607</td>\n",
              "      <td>2.924329</td>\n",
              "      <td>7.799534</td>\n",
              "      <td>19.272610</td>\n",
              "      <td>14.749915</td>\n",
              "      <td>31.202568</td>\n",
              "      <td>0.021697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>glove top-5</th>\n",
              "      <td>20.861253</td>\n",
              "      <td>15.091167</td>\n",
              "      <td>37.972931</td>\n",
              "      <td>4.497306</td>\n",
              "      <td>3.088513</td>\n",
              "      <td>9.974654</td>\n",
              "      <td>19.607727</td>\n",
              "      <td>14.198037</td>\n",
              "      <td>35.709369</td>\n",
              "      <td>0.021697</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-222b47f5-d4a6-47c6-90c3-c3bbb7e0c1a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-222b47f5-d4a6-47c6-90c3-c3bbb7e0c1a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-222b47f5-d4a6-47c6-90c3-c3bbb7e0c1a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-119be21b-6a7e-4d88-bb30-99ee9c8370c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-119be21b-6a7e-4d88-bb30-99ee9c8370c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-119be21b-6a7e-4d88-bb30-99ee9c8370c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3b9bb7ae-0a8c-4815-862f-c4b31342b363\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3b9bb7ae-0a8c-4815-862f-c4b31342b363 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yha_TYLBS3Ab",
        "outputId": "68f4d8ad-bd3c-43d4-906d-68541e229ce8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "all_summaries[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc': 'philadelphia, pennsylvania (cnn) -- i wore a path between washington and philly for interviews and shoots for our recent \"cheating death\" special with dr. sanjay gupta..in the field: jeremy harlan.my job as a photojournalist is to shoot and edit stories for cnn and make sure my news team eats well on the road..on assignment: philadelphia, pennsylvania.now, i love cheese steaks as much as the next guy. but my arteries can only take so much steak, cheese and peppers. so here are a few places that are great alternatives in the city of brotherly love..reading terminal market.hours: 8 a.m.-6 p.m. monday through saturday; 9 a.m.-5 p.m. sunday.cuisine: you name it, the market has it.how do i describe the reading terminal market? it\\'s like the las vegas of food. everywhere you turn, there\\'s something interesting to see, smell and taste. it is food sensory overload..the hardest part of going to the market is not eating the very first thing you see. give yourself 15 minutes to walk through the market before deciding where to spend your hard-earned lunch dollar..i saw apple dumplings, muffalettas, spanakopita, pulled pork, snapper soup, strombolis, all the fresh veggies, meat and cheese you could throw in your fridge and of course cheese steaks..i finally decided to stop at dinic\\'s pork and beef for the famous roast pork sandwich. the service was fast and friendly. the sandwich was fantastic, and if you sit at the counter long enough, you might hear one of philly\\'s finest talk about the crazy arrest of the day..and make sure you save room for a smooth and creamy cupcake (or two) from the flying monkey..magic carpet.hours: 10:30 a.m.-3 p.m..cuisine: mediterranean/vegetarian.the first thing i ask our local contact on a story is where i\\'m eating lunch. if you ask holly auer, university of pennsylvania hospital\\'s senior medical communications officer, she\\'ll immediately say, \"magic carpet.\".this vegetarian culinary delight is actually a small vendor trailer just across from penn hospital. if you haven\\'t been to philly, you need to know this city takes its street vendor food pretty seriously..i still scratch my head at how these folks make so much delicious food in such cramped quarters. my personal favorite at magic carpet is a pita sandwich stuffed with grape leaves. it\\'s so good, i usually eat two..maybe the best part: the sandwiches are around five bucks. definitely the worst part: the long line of neurosurgeons, med students, nurses and cardiologists waiting for their delicious ride on the carpet, too..the franklin fountain.hours: noon-midnight.cuisine: ice cream.the franklin fountain is a cool escape back to the early 20th-century ice cream fountain shop. although it opened in the summer of 2004, you would think it was 1944 when you walk in the door. the owners left no detail ignored in building this dairy delight..the fountain offers sundaes, splits, ice cream waffle sandwiches, fresh pies, house-made cakes, phosphates and america\\'s oldest soft drink, just to name a few..coffee lovers will enjoy the lightning rod sundae. everyone will enjoy his or her trip back in time..',\n",
              " 'gen_summ': \"the hardest part of going to the market is not eating the very first thing you see. give yourself 15 minutes to walk through the market before deciding where to spend your hard-earned lunch dollar. . now, i love cheese steaks as much as the next guy. but my arteries can only take so much steak, cheese and peppers. so here are a few places that are great alternatives in the city of brotherly love. . reading terminal market . this vegetarian culinary delight is actually a small vendor trailer just across from penn hospital. if you haven't been to philly, you need to know this city takes its street vendor food pretty seriously. . my job as a photojournalist is to shoot and edit stories for cnn and make sure my news team eats well on the road. . \",\n",
              " 'true_summ': 'cnn\\'s jeremy harlan talks about his favorite places to eat in philadelphia . reading terminal market is the \"las vegas of food,\" harlan says . franklin fountain is a cool escape back to early 20th-century soda fountain . '}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uZR5MRhhD9f"
      },
      "source": [
        "# my_text = \"\"\"All right, so we had quite a bit of reading today. Chapter one of, and we're gonna start with Baker, Introduction to Old English, and move on to the little bit of reading that you had in Mitchell and Robinson. So chapter one on the Anglo-Saxons and their language, this mostly just went into quite a bit more depth of my, a deeper version of my very quick snapshot micro history lesson from the first day of class. Any questions about chapter one about introduction to Old English Baker, chapter one? Yeah, go ahead. Oh, that's not in chapter one. Chapter one is just the history. We're going through in order. So everybody, please take out their Baker textbook because this is, we need this, whether you have the opening files from on Canvas or soon the book itself. All right, so chapter one was just the history. Chapter two So I'm gonna go through the kind of greatest hits of this of this chapter and we'll and chapters three and four and then we will we will I'll take questions as they as they arise So one of the things one of the most important things on page 12 is that length, vowel length, is important in pronunciation. So when you see this long mark over the E of hey, you really actually hold it hey as in, as longer than if it did not have that long mark. So listen to yourself, they give a good example in the parenthetical on page 12. Listen to yourself as you pronounce beat and bead. We naturally hold the E longer when we say bead versus beat. And that's the kind of difference in length that you're going to want to observe when you say a long vowel versus a short vowel in Old English. Vowels in Old English, Old English has seven vowels functionally. It has the five that we're of, plus ash and why. And they are pronounced, I'm going down the list here on page 13. So the only hard or the only non-modern English sound of those is the last one, the Y, which is pronounced, as if you're saying, tu, or dure. So, kining, not kining, kining, kying, brid, bride. The other most important thing about these vowels is the ash, that A ligature, which when I write it on the board, I'll write like that. This vowel is always pronounced A, as in cat. Make sure to pronounce it that way, even when it's hard to do so. So, quatt, that first word of that first email I sent you at the beginning of the semester, that becomes modern English. What? Quatt is not that hard to say. Quatt, however, the old English word for where, is hard to say. But still stay with me in Duckland, quack, quack, quack, quack, quack, even when it's hard, quack, all right? You don't need to worry about i.e. that last of those vowels on page 13. One last thing at the bottom of page 13, and it's hard to do because our modern English inclination to not pronounce final vowels precisely, final unack sounded vowels precisely is so strong. We tend to reduce everything to a schwa, that sort of neutral-a sound. But it is important because in Old English, that date of singular cune-ing-gay ends in an E versus genitive plural cune-ing-gah, right? That last vowel, that is the only way to distinguish those two different versions of that word. So just when you're reading out loud, try to distinguish those vowels at the ends of words. Diff thongs on page 14. The most important thing to remember here is to really say these as one syllable, not two syllables. So, Bae-wolf, that E-O of Bae-wolf, that should be it. The name is two syllables. Bae-wolf, right? The E-A represents a diphthong that started with A and glided to A. This is hard to do in modern English. There's a reason that we don't pronounce words like this anymore, but that word, phylon, rad. I was taught to pronounce it sort of ea rather than ash a. ea is a lot easier to say frankly, but try'sh A and see if you can get it into your voice. So file on rad. Yeah, Tara. Top of 14. Any questions about vowels or diphthongs? All right, consonants, I'm not gonna go over all of these in detail. The most important thing to remember is just that there are no silent consonants. So if it's there on the page, say the letter. Let's see. I think the most challenging ones, and we'll get to these in a little bit, the most challenging ones are the C and the G, just because they have such a range of pronunciation. C, this is number six on page 15. C is pronounced k when it has no little dot over it and chah if it does. But it's never pronounced s. G is trickier. So G has several options. Dotless G is pronounced g, as you would expect, when it comes at the beginning of a word or a syllable. Between voiceless sounds, dotless G is pronounced G. So like, dog-ass. You just kind of, this G, you just sort of sort of swallow it. So instead of dog-goss it's like dog-goss Everyone try that dog-goss? Dog-goss? Yeah, okay. We'll get practice later on CG is pronounced J so bridge bridge edge number eight there um and H is always H at the beginning, but it all at the end it has that h sound. So nicht, naach, ther, dwerf, for dwarf. And SC is usually pronounced, shh. So what looks like skip is actually ship. What looks like ask is actually ash. Rushan, there are a few exceptions to this, but that's pretty safe. Any questions on these? We'll get practices we all read aloud together. Oh, by the way, I did put up a video of me reading the Old English Roon poem on Canvas. So if you haven't checked that out, it's a good way to just get the sound of Old English in your ears as you're working at home. All right, so more about vowels now, 2.2 at the bottom of page 16, leading into 17. I'm mutation on page 17. I'm mutation is a shift in the quality of a vowel, so it's pronounced with the tongue higher and farther forward than usual. And there's actually a useful diagram on pages in Mitchell and Robinson. On page 22 of Mitchell and Robinson, it has a kind of a diagram of where in the mouth the tongue is located when these vowels are pronounced. You might find it useful. What's nice about table 2.1 is that it gives you the kind of key for how unmutated vowels become mutated vowels. You do not need to memorize this table. It will never show up on a quiz. but I do encourage you to sort of practice making those sounds, those shifts from A to A, A to E, O to A, O to E. The reason for doing that is because it will help you recognize a lot of irregular, English nouns take I'mutation in the plural. This is how we go from mouse to mice, goose to geese. That's the process. And you can see goose that O becomes E, anyway. Don't need to worry about it too much right now though. One little point I will note on page 18 though is that some modern English words have the way that I mutation works often leads to ash going turning into EA. So for example, you see halon becomes there. That will become heel in modern English. Similarly, rad will become read in modern English. Again, not something you need to memorize, but just something to know. Like if you're guessing about the meaning of a word and you see an ash, try turning it into an EA and see if it makes sense. This process, by the way, whereby the vowel changes, but the consonants don't, that's very typical of the linguistic evolution of English. Vowels are much, much more inclined to change than consonants, which is not to say that consonants don't change, they do, but it's just something to remember. Any questions so far? All right, page 19, take a look at the fuller middle of the page, the fuller explanation, well, top-ish in middle of the page, these fuller explanations of C and especially G. I've already gone over the difference in G word initial as goad, glad versus the kind of swallow G of doggos, sorgorgha, seagahn, seagahn. Very importantly, that dotted G is almost always pronounced Y. So Yistren die for yesterday. Slayin, sl. May. May. Sale. Meaning sale. Salehudah. The only difference really is certain, when you have N and then dotted G right after it, it's pronounced just like in modern English angel, Sangia. And then I think that's about it that, oh, accentuation, this is also important, bottom of page 20. This makes life so much easier. All Old English words are accented on the first syllable. Except, it's a pretty limited exception. Words with that prefix GE, or the YI, the this prefix. Here, we pronounce the, we accent the second syllable. But other than that, everything is pronounced on the first syllable. Only other exception to that is verbs with prefixes are accented after the prefix. So the examples that they give down there for waer than accented on the second syllable, but the noun derived from it for weird is still accented on the prefix. So when in doubt, accent the first syllable. And then you have a little summary of the pronunciation rules on the bottom of in 2.7 on the bottom of page 21. All right. Any questions there? Okay, basic grammar, a review. I'm not gonna go into, I not going to go through all of this, but I am going to emphasize the importance of understanding the difference between a clause and a phrase, okay? So a phrase is a cohesive group of words that lack a subject and a verb, whereas, or rather a subject in a finite verb, a clause is a group of words that has a subject in a finite verb, okay? And a finite verb just means like a conjugated verb that's inflected as distinct from an imperative or an infinitive or something like that. Okay? So, in the example that I put up on the board here, I put it on the table that I bought in Greece. Let's find some phrases and clauses. The reason it's important to be able to find phrases and clauses in any sentence is that every time you translate an old English sentence, you are looking for the main for the subject and the main verb. So what is the main verb of this sentence? Yeah. Yeah, exactly. So here's the subject and here's the verb. And yet we have other verbs, right? What is the other verb? Bought exactly. So we know that there are how many clauses in this sentence. Two, exactly. There will always be as many clauses as there are subjects and verbs. But this one is governing this one. How is it doing so? What are the phrases that we can see and what kinds of phrases are they? Yeah, go ahead. Okay. All right, good. Very good. So here we have a noun clause. Here we have a long prepositional phrase with an embedded clause and then a further embedded phrase right there. Good. You don't need to worry too much about the different kinds. I'm never going to test you on, is this a noun clause? Is it an adverb clause? Whatever. That I do not care about. What I do care about is your ability. And you don't have to diagram sentences like these on exams. But you will need effectively to be able to diagram the sentences in order to be able to translate correctly. Okay? So I'll highlight the bottom of page 25. This is in 3.13. The finite clause must contain a finite verb. In general, finding and understanding the finite verb is the key to decoding complex clauses and sentences in Old English. And so it is essential that you get familiar with the finite verb paradigms. You will memorize the finite verb paradigms and do course. I say this as a preview of coming attractions. The reason that the verb is more important than the subject in Old English is that the verb is always there, whereas the subject can be implied as it is in some modern languages as well. All right. Questions? I'll just say very quickly on page 26 when it says the past participle is also used to form a paraphrastic passive. paraphrastic just means using multiple words to carry the meaning. So using the words, the words most lovely as opposed to loveliest, that's an inherently paraphrastic way of speaking. So the king was slain as opposed to just the king died, et cetera. Let's see. Any questions leading up to 3.4 on page 30? All right. Subjects, the elements of the sentence or the clause. So the subject names what the sentence or clause is about. It may be a noun, a pronoun, a noun, phrase or a list. I mean, namely a compound subject. Top of page 31, pay close attention here. In Old English, as in modern English, subjects can be simpler complex. So what's different though is that in Old English, a compound subject can be split. If I say in modern English, my friends and I are going to the store, I would never split up my friends and I in the sentence. That would be very, very strange. I would not say my friends are going to the store and I. In Old English, they do that all the time. So, for example, my shield protects me and my sword. In modern English, that sentence is unambiguous, if a little weird. The me and my sword are the compound direct object of protects. In old English, however, my shield protects me and my sword. The only way you're going to be able to determine whether my sword is, as it is in modern English, an object of the verb protect, or part of the compound subject, i.e. my shield and my sword protect me, the only way you're going to be able to distinguish is based on the case, the grammatical case of the word sword, all right? Which is one of the reasons that knowing the paradigms is so absolutely crucial to being able to decode these sentences. Old English differs from modern English in that it often omits the subject when the context makes it obvious what it is. It says there. I would actually say that's still at the top of page 31. I would actually say that Old English often omits the subject even when context does not make it particularly clear what it is, which especially in poetry, which is one way that poets, Old English poets could get kind of nice literary mileage out of the inherent ambiguity of the language, but it also makes things harder for us as non-native speakers and readers of the language. So bear these things in mind as you're moving forward. Yeah. In the case of only one shut up here, you have like me on my shield, I see my sword. Presumably this would all be reflected in the verb and that like you would expect the verb to reflect for plural. Is it going to come from conflict? Excellent. Yes. And to ask if Arabic does weird things with this were like it might not reflect clearly just for kicks. No, you're absolutely right. It's a totally great point. You're right. We would be able to distinguish based on in this case, but not necessarily in others. Excellent point. Because if it were say my companions protect me and my right, then it would still be ambiguous. But very good right. Next thing I want to highlight is the top of page 33. Because the direct object is usually defined as the noun, this is from the previous page, usually defined as the pronoun, or noun phrase that receives the action of the verb. They explain some sort of subtleties of that. Top of page 33. In modern English, the direct object usually follows the verb and never has a preposition in front of it. In old English, the direct object may fall over the verb, but it may also precede the verb, especially when the object is a pronoun. Generally, it's in the accusative case, but not always. And then an indirect object is a thing that has some indirect relationship to the action of the verb. Basically, the indirect object is anything that is not a direct object. So if you, and you really don't need to worry about, again, I'm not going to say what is the direct object. I'll just expect you to be able to translate. But the variable word order that is alluded to at the top of page 33, the direct object may follow the verb, it may also precede it. This is something that we're going to hear a lot. Word order is extremely flexible in Old English compared to modern English. And the reason for that is that it's a case-based language, right? We learn a lot of the features, the functions of the word in a given sentence, based on the case endings. Modern English has lost almost all its case endings. Who and whom is one sort of increasingly archaic exception to that, where who is the subject, whom is the object? But apart from and he, him, right? There are, she, her, there are, we do have cases, but increasingly they are obsolete and not, they're only in pronouns, not in nouns. But because Old English communicates so much more information through the endings of the words themselves, you can have word order that is what we would think of as unnatural. And you have to kind of rearrange the pieces of the sentence, the pieces of the puzzle as it were in order to decode it. We'll come back to this again and again, but it's worth telling yourself from the beginning that this is true. Any questions about chapter three and this very basic, very quick grammar review? All right, let's move on to chapter four and cases. So page 34, case is the inflection of nouns, pronouns and adjectives to signal their function in sentences and clauses. This is exactly what we were talking about just before. Modern English case has almost disappeared. Again, except in pronouns. The cases in Old English are nominative, accusative, genitive, date-ive, and the increasingly archaic as we move. It's actually archaic, even a little archaic, even from the beginning of our written record, the instrumental. So the nominative case is quite easy because it has, as Baker says, had has few functions and there are few complications. Basically, it's the subject. It's also the complement. So the complement is the word on the other side of a linking verb such as to be. So sayosunna is swi-da-broad. The sun is very broad. Broad there is in the nominative because it is the complement of su-na. And then since Old English does not have a vocative case like some languages. The nominative is used for direct address as well. But those are really the only things that it gets used for. The accusative case is also pretty straightforward because direct objects of transitive verbs are typically in the accusative case. So thus, in the sentence at the top of page 37, his aga and swastore the burriida, his leech, his own sister buried his corpse, leech is in the accusative. Some prepositions always take the accusative, no matter what. And sometimes you have an accusative used adverbially in expressions of time, but you don't need to worry too much about that. All right, the genitive case modifies or limits a word, this is page 37, by associating it with something. So for example, in the phrase, fast-kinningus sweared, the king's sword, the sense of sword is modified by our saying that it belongs to the king. We're not speaking of any just sword, or just any sword. Most genitives will fall into one of three categories. The possessive genitive is the one that we're most familiar with. The King's sword, Saint Edmund's feast day. But the partitive genitive is an extremely important because extremely common use of the genitive in Old English. So for example, Alch, Tha-Ramanna, each of the men, Elra, Kuningah, Best of all kings. As the translations with Av suggest, we have a roughly similar construction made with the preposition of, but Old English doesn't need the preposition because it has the genitive case to sort of embed that OV indirectly into the word itself. So make sure that you're on the lookout for that. And notice already, just in those two examples, how in one case the partitive genitive comes after the adjective, ouch, ail ra mam na. And in the other one, ail ra kuning best, the partitive genitive comes before. Again, typical. You've just got. So one piece of advice I like to give is to kind of like, we have very rigid word order in modern English. In order to read old English, well, you kind of have to almost like, I think of it as like, relaxing. Our sense of what word order can do. And you have to develop a kind of almost like flexibility of mind in saying, OK, well, what if this word goes with that word, even though they're separated by like an entire line of poetry and so on and so forth? Finally, the third element of the, of the, or third aspect of the genitive is the descriptive. So that lump shall bound, weatus, hewis. The lamb must be of a white color. And I mean, they say it's more idiomatic to say is white in color. Sure, I guess. But like, that's still, I don't know, that still sounds basically right to me. The lamb is of a white color. Maybe that is a little weird. In any event, people in Old English did it all the time. So those are the three. And then the last little bit, the last little point at the top of page 38. A few prepositions take the genitive case. It's rare, but it can happen. And a few verbs have genitive direct objects. And that's just something you'll have to learn as you learn the verbs. Some verbs take the, most verbs take the accusative. A very few take the genitive. Quite a few actually, as we'll see, take the date of. So any questions on nominative genitive, nominative, accusative or genitive before we go on to dative, which is the sort of catch all? All right. So 4.2.4, page 38. In all of the Germanic languages, the dative case is in a malgum of several older cases that have fallen together. So date of, lockative, ablative, and instrumental. Pre-written versions of Germanic languages, we think had all of these cases, but for the most part, they've all sort of like collapsed into the data by the time that we're working. This is good, and as much as it means you have fewer paradigms to memorize, it's bad in the sense that the data can do almost anything. We will discover, all right? Or it's not bad. It's confusing potentially. So I'm going to go through some of the most important uses of the date of case, and then we'll take questions. So the date of interest signifies that in some way that one is in some way interested in the outcome of an action, this category includes the indirect object. So Yifim has sweared. But the date of of interest also covers situations in which something has been taken away and is therefore sometimes called the date of disinterest. Benam heihim, his bishop, Shira, he took his bishop, bishop Rick away from him. One other aspect, one other function of the date of case that actually, oh yeah, there it is at the bottom of the page, I'll get back to that in one sec. The direct object, so some verbs have their direct objects in the date of case, I already, I mentioned that briefly before. It's not that uncommon actually. So just, yeah, and you'll just have to look up the word in order to know. Fortunately, our glossaries indicate which case the verb will take as a direct object. So for example, here on, which is the example that they give right there, oh I guess they gloss it under. It takes a little while to get the hang of using old English glossaries because there's a lot of words can be spelled a lot of different ways. There's no such thing as standardized spelling quite yet. But if you look up Huron on page 333 of the glossary to hear, to listen to, and then to obey, and then it includes in parentheses with the data. So the glossary will guide you.\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = \"\"\" In India, 2023 will be remembered as the year we went to the Moon. On 23 August, massive celebrations broke out across the country when Chandrayaan-3 touched down in the lunar south pole region - an area on the Moon's surface that no-one had reached before. With this, India also joined an elite club of countries to achieve a soft landing on the Moon, after the US, the former Soviet Union and China. In the following months, India continued its stride into space - by sending an observation mission to the Sun and then by carrying out a key test flight ahead of its planned mission to take astronauts into space in 2025. We look back at an eventful year when India's strides into space made global headlines. It was \"20 minutes of terror\" for scientists at the Indian Space Research Organisation (Isro) as the Vikram lander, carrying the Pragyaan rover in its belly, began its descent to the Moon's surface.\n",
        "The lander's speed was gradually reduced from 1.68km per second to almost zero, enabling it to make a soft landing in the south pole region where the surface is \"very uneven\" and \"full of craters and boulders\".\n",
        "\"India is on the Moon,\" a triumphant Isro chief S Somanath announced - and with that the country entered the history books.\n",
        "Over the next 10 days, space scientists - and the rest of the country - followed every move made by the lander and the rover as they gathered data and images and relayed them back to Earth for analysis. So we saw images of the six-wheeled rover sliding down from the lander's belly and taking its first steps on the lunar soil. Moving at a speed of 1cm per second, it \"traversed over 100m [328 feet]\" and at times re-routed to avoid falling into craters.\n",
        "Some of their findings that show a sharp difference in temperatures just above and below the lunar surface and confirmed presence of a host of chemicals, especially sulphur, in the soil have enthused space scientists and the scientific community at large. One of the highlights, Isro said, was Vikram's \"hop experiment\". The agency said that when the lander was \"commanded to fire its engines, it rose up by about 40cm [16 inches] and landed at a distance of 30-40cm\". This \"successful experiment\" means the spacecraft could be used in future to bring samples back to the Earth or for human missions, it added.\n",
        "And earlier this month Isro said it had successfully brought back into Earth's orbit a part of the rocket that carried Chandrayaan-3 to Moon.\n",
        "The \"propulsion module\", which had detached from the Vikram lander after ferrying it close to the Moon, had re-entered Earth's orbit after a series of complex manoeuvres.\n",
        "Together, the hop experiment and the return of the propulsion module to Earth's orbit are crucial for Isro's future plans to bring back samples or return astronauts from Space.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "k213sOqk8tyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.pipeline.sentencizer import Sentencizer\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "sentencizer = Sentencizer()\n",
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhKZxHIj7bks",
        "outputId": "5f8e866e-cdff-48cb-b73b-ffa537138602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7dce98deb700>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(my_text.replace(\"\\n\", \"\"))\n",
        "my_text_sentences = [sent.text.strip() for sent in doc.sents]"
      ],
      "metadata": {
        "id": "sIqAlBqD74hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_new_text_sentences = []\n",
        "for sent in my_text_sentences:\n",
        "    if len(sent) >= 20:\n",
        "        my_new_text_sentences.append(sent)\n",
        "my_text_sentences = my_new_text_sentences"
      ],
      "metadata": {
        "id": "RGiE3yGi793B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(my_text_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imk_lBYl8Vqc",
        "outputId": "598d0f51-2129-4ab7-ed90-678f0ea47c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the model from drive\n",
        "\n",
        "# pickle_file_path = '/content/drive/MyDrive/extractive_summarizer.pkl'\n",
        "# with open(pickle_file_path, 'rb') as file:\n",
        "#     loaded_model = pickle.load(file)"
      ],
      "metadata": {
        "id": "NAQRkKOw-lTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_emb = get_embedding(my_text)\n",
        "\n",
        "my_x = []\n",
        "for sent in my_text_sentences:\n",
        "    sent_emb = get_embedding(sent)\n",
        "    t = np.concatenate((sent_emb, text_emb))\n",
        "    my_x.append(t)\n",
        "my_x = np.asmatrix(my_x)\n",
        "predicted_scores = get_values(my_x, model)\n",
        "# k = 10\n",
        "k = 5\n",
        "summary_sent_id = get_top_k(my_x, predicted_scores, k)\n",
        "summary_sent_id.sort()\n",
        "generated_summary = join([my_text_sentences[idx] for idx in summary_sent_id])"
      ],
      "metadata": {
        "id": "S2DJNTzv3eOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "dikns-HM6wxB",
        "outputId": "0247825c-c522-4a96-c169-2b8ba459f467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In India, 2023 will be remembered as the year we went to the Moon. . The lander\\'s speed was gradually reduced from 1.68km per second to almost zero, enabling it to make a soft landing in the south pole region where the surface is \"very uneven\" and \"full of craters and boulders\". . Over the next 10 days, space scientists - and the rest of the country - followed every move made by the lander and the rover as they gathered data and images and relayed them back to Earth for analysis. . Moving at a speed of 1cm per second, it \"traversed over 100m [328 feet]\" and at times re-routed to avoid falling into craters. . This \"successful experiment\" means the spacecraft could be used in future to bring samples back to the Earth or for human missions, it added. . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}